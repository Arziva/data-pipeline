{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqlObef6gl+8HmRXQAb7ab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arziva/data-pipiline/blob/main/xml2json1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fpn7iTAGM8xh"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "\n",
        "def parse_pubtator_xml(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    documents = root.findall('document')\n",
        "    for doc in documents:\n",
        "        passages = doc.findall('passage')\n",
        "        abstracts = [p for p in passages if p.findtext('infon[@key=\"section_type\"]') == 'ABSTRACT']\n",
        "        for i, abstract in enumerate(abstracts):\n",
        "            offset = abstract.find('offset').text\n",
        "            text = abstract.find('text').text\n",
        "\n",
        "            entities = []\n",
        "            annotations = abstract.findall('annotation')\n",
        "            for annotation in annotations:\n",
        "                entity_id = int(annotation.get('id'))\n",
        "                entity_label = annotation.findtext('infon[@key=\"type\"]')\n",
        "                start_offset = int(annotation.find('location').get('offset'))\n",
        "                end_offset = start_offset + int(annotation.find('location').get('length'))\n",
        "                entities.append({\n",
        "                    'id': entity_id,\n",
        "                    'start_offset': start_offset,\n",
        "                    'end_offset': end_offset,\n",
        "                    'label': entity_label\n",
        "                })\n",
        "\n",
        "            relations = []\n",
        "            relation_elements = abstract.findall('relation')\n",
        "            for relation in relation_elements:\n",
        "                relation_id = int(relation.get('id'))\n",
        "                from_id = int(relation.get('from'))\n",
        "                to_id = int(relation.get('to'))\n",
        "                relation_type = relation.get('type')\n",
        "                relations.append({\n",
        "                    'id': relation_id,\n",
        "                    'from_id': from_id,\n",
        "                    'to_id': to_id,\n",
        "                    'type': relation_type\n",
        "                })\n",
        "\n",
        "            # comments = []\n",
        "            # comment_elements = abstract.findall('Comment')\n",
        "            # for comment in comment_elements:\n",
        "            #     comment_id = int(comment.get('id'))\n",
        "            #     comment_text = comment.text\n",
        "            #     comments.append({\n",
        "            #         'id': comment_id,\n",
        "            #         'comment': comment_text\n",
        "            #     })\n",
        "\n",
        "            data = {\n",
        "                #'id': i+1,\n",
        "                'text': text,\n",
        "                'entities': entities,\n",
        "                'relations': relations,\n",
        "                #'comments': comments\n",
        "            }\n",
        "\n",
        "            json_data = json.dumps(data, indent=4)\n",
        "\n",
        "            # Write JSON data to a file\n",
        "            with open(f'{offset}.json', 'w') as json_file:\n",
        "                json_file.write(json_data)\n",
        "\n",
        "# Example usage\n",
        "parse_pubtator_xml('biocxml.xml')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "\n",
        "def parse_pubtator_xml(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    documents = root.findall('document')\n",
        "    with open('output.jsonl', 'w') as jsonl_file:\n",
        "        for doc in documents:\n",
        "            passages = doc.findall('passage')\n",
        "            abstracts = [p for p in passages if p.findtext('infon[@key=\"section_type\"]') == 'ABSTRACT']\n",
        "            for i, abstract in enumerate(abstracts):\n",
        "                offset = abstract.find('offset').text\n",
        "                text = abstract.find('text').text\n",
        "\n",
        "                entities = []\n",
        "                annotations = abstract.findall('annotation')\n",
        "                for annotation in annotations:\n",
        "                    entity_id = int(annotation.get('id'))\n",
        "                    entity_label = annotation.findtext('infon[@key=\"type\"]')\n",
        "                    start_offset = int(annotation.find('location').get('offset'))\n",
        "                    end_offset = start_offset + int(annotation.find('location').get('length'))\n",
        "                    entities.append({\n",
        "                        'id': entity_id,\n",
        "                        'start_offset': start_offset,\n",
        "                        'end_offset': end_offset,\n",
        "                        'label': entity_label\n",
        "                    })\n",
        "\n",
        "                relations = []\n",
        "                relation_elements = abstract.findall('relation')\n",
        "                for relation in relation_elements:\n",
        "                    relation_id = int(relation.get('id'))\n",
        "                    from_id = int(relation.get('from'))\n",
        "                    to_id = int(relation.get('to'))\n",
        "                    relation_type = relation.get('type')\n",
        "                    relations.append({\n",
        "                        'id': relation_id,\n",
        "                        'from_id': from_id,\n",
        "                        'to_id': to_id,\n",
        "                        'type': relation_type\n",
        "                    })\n",
        "\n",
        "                # comments = []\n",
        "                # comment_elements = abstract.findall('Comment')\n",
        "                # for comment in comment_elements:\n",
        "                #     comment_id = int(comment.get('id'))\n",
        "                #     comment_text = comment.text\n",
        "                #     comments.append({\n",
        "                #         'id': comment_id,\n",
        "                #         'comment': comment_text\n",
        "                #     })\n",
        "\n",
        "                data = {\n",
        "                    #'id': i+1,\n",
        "                    'text': text,\n",
        "                    'entities': entities,\n",
        "                    'relations': relations,\n",
        "                    #'comments': comments\n",
        "                }\n",
        "\n",
        "                json_data = json.dumps(data)\n",
        "                jsonl_file.write(json_data + '\\n')\n",
        "\n",
        "# Example usage\n",
        "parse_pubtator_xml('biocxml.xml')\n"
      ],
      "metadata": {
        "id": "eXtLvcJdhOrJ"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}